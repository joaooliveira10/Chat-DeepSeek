# Chat DeepSeek ğŸ¤–ğŸ’¬

Uma interface de chat simples para interagir com o modelo DeepSeek, usando Streamlit e LangChain.

## ğŸ“‹ VisÃ£o Geral

Chat DeepSeek Ã© uma aplicaÃ§Ã£o que permite conversar com o modelo DeepSeek atravÃ©s de uma interface web intuitiva. A aplicaÃ§Ã£o utiliza:

- **Streamlit** para a interface de usuÃ¡rio
- **LangChain** para integraÃ§Ã£o com o Ollama
- **Modelo DeepSeek** executando localmente via Ollama

## âœ¨ Funcionalidades

- Interface de chat amigÃ¡vel
- HistÃ³rico de conversas durante a sessÃ£o
- Processamento local dos dados (privacidade garantida)
- Respostas em tempo real

## ğŸ› ï¸ PrÃ©-requisitos

- Python 3.8 ou superior
- Ollama instalado localmente
- Modelo DeepSeek disponÃ­vel no Ollama

## ğŸ“¦ InstalaÃ§Ã£o

1. Clone o repositÃ³rio:

```bash
git clone https://github.com/joaooliveira10/Chat-DeepSeek.git
cd Chat-DeepSeek
```

2. Instale as dependÃªncias:

```bash
pip install -r requirements.txt
```

3. Certifique-se que o Ollama estÃ¡ em execuÃ§Ã£o e que o modelo DeepSeek estÃ¡ disponÃ­vel:

```bash
ollama pull deepseek-r1:1.5b
```

## ğŸš€ Como Usar

1. Inicie o Ollama em um terminal:

```bash
ollama serve
```

2. Em outro terminal, execute a aplicaÃ§Ã£o Streamlit:

```bash
streamlit run chat_deepseek.py
```

3. Acesse a interface web atravÃ©s do navegador (geralmente http://localhost:8501)

4. Digite suas mensagens no campo de entrada na parte inferior da tela e pressione Enter para enviar.

## ğŸ§© Estrutura do Projeto

```
Chat DeepSeek/
â”œâ”€â”€ chat_deepseek.py    # Arquivo principal da aplicaÃ§Ã£o
â”œâ”€â”€ requirements.txt    # DependÃªncias do projeto
â””â”€â”€ README.MD           # DocumentaÃ§Ã£o do projeto
```

## ğŸ”§ PersonalizaÃ§Ã£o

Para alterar o modelo utilizado, modifique a seguinte linha no arquivo `chat_deepseek.py`:

```python
llm = ChatOllama(model="seu-modelo-preferido", base_url='http://localhost:11434')
```
